# EmoGestureAI

Un sistema inteligente que combina Visión Artificial y Aprendizaje Profundo para unir el entretenimiento y el análisis emocional en tiempo real.

## Objetivo del Proyecto
El objetivo principal de **EmoGestureAI** es desarrollar una aplicación interactiva que utilice la entrada de cámara en tiempo real para:
1. **Reconocimiento de Gestos:** Diseñado específicamente para jugar al clásico "Piedra, Papel o Tijera".
2. **Análisis de Estados Emocionales:** Detectar y clasificar expresiones faciales y sentimientos (alegría, sorpresa, frustración, etc.) durante el juego.
3. **Análisis de Comportamiento:** Proporcionar una correlación entre la respuesta emocional del usuario y sus patrones de juego.

## Miembros
* **Daniel Chacón Bautista** - Desarrollador e Investigador
* **Álvaro Benito Benito** - Desarrollador e Investigador
* **David** - Desarrollador e Investigador
* **Javier** - Desarrollador e Investigador

## Organización del Repositorio
El proyecto está organizado siguiendo una arquitectura modular para garantizar un código limpio y escalable:

* **`src/`**: Contiene el código fuente principal del proyecto.
    * `main.py`: Punto de entrada de la aplicación.
* **`docs/`**: Documentación técnica, diagramas de arquitectura y la memoria final del grado.
* **`environment/`**: Archivos de configuración del entorno de desarrollo, incluyendo `requirements.txt` para la gestión de librerías.
* **`.gitignore`**: Especifica los archivos que Git debe ignorar (archivos temporales, entornos virtuales, etc.).
* **`README.md`**: Descripción general del proyecto e instrucciones (este archivo).

---
*Este proyecto se desarrolla como parte de la asignatura de **Proyecto de big data e inteligencia artificial**.*